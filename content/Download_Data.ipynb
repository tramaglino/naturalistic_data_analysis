{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Data\n",
    "\n",
    "*Written by Luke Chang*\n",
    "\n",
    "Throughout this course we will be using two open source naturalistic datasets to demonstrate how to use different analytic techniques. If you end up using any of this data in a paper, be sure to cite the original papers.\n",
    "\n",
    "The **Sherlock** dataset contains 16 participants that watched 50 minutes of Sherlock across 2 scanning run (i.e., Part1 & Part2) and then verbally recalled the narrative in the scanner using a noise cancelling microphone. The TR was 1.5. If you would like to access the stimuli, we have included the video from Part1 (1st 25min) and an audio recording of the show can be downloaded in the stimuli folder of this [openneuro](https://openneuro.org/datasets/ds002345/versions/1.0.1) page. We have preprocessed the data using fmriprep and performed denoising. See the [Preprocessing](http://naturalistic-data.org/features/notebooks/Preprocessing.html) tutorial for more details. Note that we have also *cropped* the viewing files so that each subject has the same number of TRs and are aligned in time at the start of the movie. The Recall data has not been cropped, but we have included the details of when the subjects recall specific scenes in the `Sherlock_Recall_Scene_n50_Onsets.csv` in the onset folder. Finally, we have also included some scene annotations shared by the authors in the `Sherlock_Segments_1000_NN_2017.xlsx` file in the onsets folder.\n",
    "\n",
    "    Chen, J., Leong, Y., Honey, C. et al. Shared memories reveal shared structure in neural activity across individuals. Nat Neurosci 20, 115â€“125 (2017). https://doi.org/10.1038/nn.4450\n",
    "\n",
    "The **Paranoia** dataset contains 23 participants who listened to 22 minute original narrative that describes an ambiguous social scenario. It was written such that some individuals might find it highly suspicious. The transcript and audio recording can be downloaded in the stimuli folder on [openneuro](https://openneuro.org/datasets/ds001338/versions/1.0.0). The TR was 1s and there was a 3 sec fixation before the beginning of each run.\n",
    "\n",
    "    Finn, E.S., Corlett, P.R., Chen, G. et al. Trait paranoia shapes inter-subject synchrony in brain activity during an ambiguous social narrative. Nat Commun 9, 2043 (2018). https://doi.org/10.1038/s41467-018-04387-2\n",
    "\n",
    "The datasets are being shared using [DataLad](https://www.datalad.org/) on the [German Neuroinformatics Node](http://www.g-node.org/), which is an international forum for sharing experimental data and analysis tools.\n",
    "\n",
    "In this notebook, we will walk through how to access the datset using DataLad. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLad\n",
    "\n",
    "The easist way to access the data is using [DataLad](https://www.datalad.org/), which is an open source version control system for data built on top of [git-annex](https://git-annex.branchable.com/). Think of it like git for data. It provides a handy command line interface for downloading data, tracking changes, and sharing it with others.\n",
    "\n",
    "While DataLad offers a number of useful features for working with datasets, there are three in particular that we think make it worth the effort to install for this course.\n",
    "\n",
    "1) Cloning a DataLad Repository can be completed with a single line of code `datalad clone <repository>` and provides the full directory structure in the form of symbolic links. This allows you to explore all of the files in the dataset, without having to download the entire dataset at once.\n",
    "\n",
    "2) Specific files can be easily downloaded using `datalad get <filename>`, and files can be removed from your computer at any time using `datalad drop <filename>`. As these datasets are large, this will allow you to only work with the data that you need for a specific tutorial and you can drop the rest when you are done with it.\n",
    "\n",
    "3) All of the DataLad commands can be run within Python using the datalad [python api](http://docs.datalad.org/en/latest/modref.html).\n",
    "\n",
    "We will only be covering a few basic DataLad functions to get and drop data. We encourage the interested reader to read the very comprehensive DataLad [User Handbook](http://handbook.datalad.org/en/latest/) for more details and troubleshooting.\n",
    "\n",
    "### Installing Datalad\n",
    "\n",
    "DataLad can be easily installed using [pip](https://pip.pypa.io/en/stable/).\n",
    "\n",
    "`pip install datalad`\n",
    "\n",
    "Unfortunately, it currently requires manually installing the [git-annex](https://git-annex.branchable.com/) dependency, which is not automatically installed using pip.\n",
    "\n",
    "If you are using OSX, we recommend installing git-annex using [homebrew](https://brew.sh/) package manager.\n",
    "\n",
    "`brew install git-annex`\n",
    "\n",
    "If you are on Debian/Ubuntu we recommend enabling the [NeuroDebian](http://neuro.debian.net/) repository and installing with apt-get.\n",
    "\n",
    "`sudo apt-get install datalad`\n",
    "\n",
    "For more installation options, we recommend reading the DataLad [installation instructions](https://git-annex.branchable.com/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datalad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data with DataLad\n",
    "\n",
    "#### Download Sherlock\n",
    "The Sherlock dataset can be accessed at the following location https://gin.g-node.org/ljchang/Sherlock. To download the Sherlock dataset run `datalad install https://gin.g-node.org/ljchang/Sherlock` in a terminal in the location where you would like to install the dataset. The full dataset is approximately 109gb.\n",
    "\n",
    "You can run this from the notebook using the `!` cell magic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad install https://gin.g-node.org/ljchang/Sherlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Paranoia\n",
    "The Paranoia dataset can be accessed at the following location https://gin.g-node.org/ljchang/Paranoia. To download the Paranoia dataset run `datalad clone https://gin.g-node.org/ljchang/Paranoia`. The full dataset is approximately 100gb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad install https://gin.g-node.org/ljchang/Paranoia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datalad Basics\n",
    "\n",
    "You might be surprised to find that after cloning the dataset that it barely takes up any space `du -sh`. This is because cloning only downloads the metadata of the dataset to see what files are included.\n",
    "\n",
    "You can check to see how big the entire dataset would be if you downloaded everything using `datalad status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad status --annex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T01:36:03.581067Z",
     "start_time": "2020-05-15T01:36:03.578577Z"
    }
   },
   "source": [
    "### Getting Data\n",
    "One of the really nice features of datalad is that you can see all of the data without actually storing it on your computer. When you want a specific file you use `datalad get <filename>` to download that specific file. Importantly, you do not need to download all of the dat at once, only when you need it.\n",
    "\n",
    "Now that we have cloned the repository we can grab individual files. For example, suppose we wanted to grab the first subject's confound regressors generated by fmriprep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad get fmriprep/sub-01/func/sub-01_task-sherlockPart1_desc-confounds_regressors.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check and see how much of the total dataset we have downloaded using `datalad status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad status --annex all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to download all of the files you can use `datalad get .`. Depending on the size of the dataset and the speed of your internet connection, this might take awhile. One really nice thing about datalad is that if your connection is interrupted you can simply run `datalad get .` again, and it will resume where it left off.\n",
    "\n",
    "You can also install the dataset and download all of the files with a single command `datalad install -g https://gin.g-node.org/ljchang/Sherlock`. You may want to do this if you have a lot of storage available and a fast internet connection. For most people, we recommend only downloading the files you need for a specific tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Data\n",
    "Most people do not have unlimited space on their hard drives and are constantly looking for ways to free up space when they are no longer actively working with files. Any file in a dataset can be removed using `datalad drop`. Importantly, this does not delete the file, but rather removes it from your computer. You will still be able to see file metadata after it has been dropped in case you want to download it again in the future.\n",
    "\n",
    "As an example, let's drop the Sherlock confound regressor .tsv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!datalad drop fmriprep/sub-01/func/sub-01_task-sherlockPart1_desc-confounds_regressors.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datalad has a Python API!\n",
    "One particularly nice aspect of datalad is that it has a Python API, which means that anything you would like to do with datalad in the commandline, can also be run in Python. See the details of the datalad [Python API](http://docs.datalad.org/en/latest/modref.html).\n",
    "\n",
    "For example, suppose you would like to clone a data repository, such as the Sherlock dataset. You can run `dl.clone(source=url, path=location)`. Make sure you set `sherlock_path` to the location where you would like the Sherlock repository installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T00:37:18.328435Z",
     "start_time": "2020-07-04T00:37:18.273502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dataset path=/Users/lukechang/Downloads/Sherlock>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import datalad.api as dl\n",
    "import pandas as pd\n",
    "\n",
    "sherlock_path = '/Users/lukechang/Downloads/Sherlock'\n",
    "\n",
    "dl.clone(source='https://gin.g-node.org/ljchang/Sherlock', path=sherlock_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a dataset instance using `dl.Dataset(path_to_data)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T00:37:21.861422Z",
     "start_time": "2020-07-04T00:37:21.857338Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = dl.Dataset(sherlock_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How much of the dataset have we downloaded?  We can check the status of the annex using `ds.status(annex='all')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T00:37:28.043472Z",
     "start_time": "2020-07-04T00:37:24.288012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1349 annex'd files (0.0 B/109.0 GB present/total size)\n",
      "1349 annex'd files (0.0 B/109.0 GB present/total size)\n"
     ]
    }
   ],
   "source": [
    "results = ds.status(annex='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it's empty, which makes sense since we only cloned the dataset. \n",
    "\n",
    "Now we need to get some data. Let's start with something small to play with first.\n",
    "\n",
    "Let's use `glob` to find all of the tab-delimited confound data generated by fmriprep. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T00:37:32.623747Z",
     "start_time": "2020-07-04T00:37:32.607905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lukechang/Downloads/Sherlock/fmriprep/sub-01/func/sub-01_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-01/func/sub-01_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-01/func/sub-01_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-02/func/sub-02_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-02/func/sub-02_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-02/func/sub-02_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-03/func/sub-03_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-03/func/sub-03_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-03/func/sub-03_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-04/func/sub-04_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-04/func/sub-04_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-04/func/sub-04_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-05/func/sub-05_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-05/func/sub-05_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-05/func/sub-05_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-06/func/sub-06_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-06/func/sub-06_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-06/func/sub-06_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-07/func/sub-07_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-07/func/sub-07_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-07/func/sub-07_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-08/func/sub-08_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-08/func/sub-08_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-08/func/sub-08_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-09/func/sub-09_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-09/func/sub-09_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-09/func/sub-09_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-10/func/sub-10_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-10/func/sub-10_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-10/func/sub-10_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-11/func/sub-11_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-11/func/sub-11_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-11/func/sub-11_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-12/func/sub-12_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-12/func/sub-12_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-12/func/sub-12_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-13/func/sub-13_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-13/func/sub-13_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-13/func/sub-13_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-14/func/sub-14_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-14/func/sub-14_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-14/func/sub-14_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-15/func/sub-15_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-15/func/sub-15_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-15/func/sub-15_task-sherlockPart2_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-16/func/sub-16_task-freerecall_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-16/func/sub-16_task-sherlockPart1_desc-confounds_regressors.tsv',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-16/func/sub-16_task-sherlockPart2_desc-confounds_regressors.tsv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = glob.glob(os.path.join(sherlock_path, 'fmriprep', '*', 'func', '*tsv'))\n",
    "file_list.sort()\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glob can search the filetree and see all of the relevant data even though none of it has been downloaded yet.\n",
    "\n",
    "Let's now download the first subjects confound regressor file and load it using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T00:37:52.115951Z",
     "start_time": "2020-07-04T00:37:40.562963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='fmriprep/su .. ressors.tsv', max=2392706.0, style=Progresâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>csf</th>\n",
       "      <th>csf_derivative1</th>\n",
       "      <th>csf_derivative1_power2</th>\n",
       "      <th>csf_power2</th>\n",
       "      <th>white_matter</th>\n",
       "      <th>white_matter_derivative1</th>\n",
       "      <th>white_matter_power2</th>\n",
       "      <th>white_matter_derivative1_power2</th>\n",
       "      <th>global_signal</th>\n",
       "      <th>global_signal_derivative1</th>\n",
       "      <th>...</th>\n",
       "      <th>motion_outlier127</th>\n",
       "      <th>motion_outlier128</th>\n",
       "      <th>motion_outlier129</th>\n",
       "      <th>motion_outlier130</th>\n",
       "      <th>motion_outlier131</th>\n",
       "      <th>motion_outlier132</th>\n",
       "      <th>motion_outlier133</th>\n",
       "      <th>motion_outlier134</th>\n",
       "      <th>motion_outlier135</th>\n",
       "      <th>motion_outlier136</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>897.394539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>805316.958867</td>\n",
       "      <td>695.564895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>483810.522970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>635.368732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>889.168301</td>\n",
       "      <td>-8.226238</td>\n",
       "      <td>67.670997</td>\n",
       "      <td>790620.267181</td>\n",
       "      <td>695.581487</td>\n",
       "      <td>0.016592</td>\n",
       "      <td>483833.605371</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>633.147820</td>\n",
       "      <td>-2.220912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>886.763733</td>\n",
       "      <td>-2.404568</td>\n",
       "      <td>5.781946</td>\n",
       "      <td>786349.918340</td>\n",
       "      <td>694.135813</td>\n",
       "      <td>-1.445674</td>\n",
       "      <td>481824.526707</td>\n",
       "      <td>2.089974</td>\n",
       "      <td>629.315476</td>\n",
       "      <td>-3.832344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>879.587127</td>\n",
       "      <td>-7.176606</td>\n",
       "      <td>51.503680</td>\n",
       "      <td>773673.513408</td>\n",
       "      <td>693.405760</td>\n",
       "      <td>-0.730052</td>\n",
       "      <td>480811.548543</td>\n",
       "      <td>0.532977</td>\n",
       "      <td>626.664425</td>\n",
       "      <td>-2.651051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>881.602440</td>\n",
       "      <td>2.015313</td>\n",
       "      <td>4.061486</td>\n",
       "      <td>777222.861394</td>\n",
       "      <td>692.787848</td>\n",
       "      <td>-0.617913</td>\n",
       "      <td>479955.002077</td>\n",
       "      <td>0.381816</td>\n",
       "      <td>628.319190</td>\n",
       "      <td>1.654765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 389 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          csf  csf_derivative1  csf_derivative1_power2     csf_power2  \\\n",
       "0  897.394539              NaN                     NaN  805316.958867   \n",
       "1  889.168301        -8.226238               67.670997  790620.267181   \n",
       "2  886.763733        -2.404568                5.781946  786349.918340   \n",
       "3  879.587127        -7.176606               51.503680  773673.513408   \n",
       "4  881.602440         2.015313                4.061486  777222.861394   \n",
       "\n",
       "   white_matter  white_matter_derivative1  white_matter_power2  \\\n",
       "0    695.564895                       NaN        483810.522970   \n",
       "1    695.581487                  0.016592        483833.605371   \n",
       "2    694.135813                 -1.445674        481824.526707   \n",
       "3    693.405760                 -0.730052        480811.548543   \n",
       "4    692.787848                 -0.617913        479955.002077   \n",
       "\n",
       "   white_matter_derivative1_power2  global_signal  global_signal_derivative1  \\\n",
       "0                              NaN     635.368732                        NaN   \n",
       "1                         0.000275     633.147820                  -2.220912   \n",
       "2                         2.089974     629.315476                  -3.832344   \n",
       "3                         0.532977     626.664425                  -2.651051   \n",
       "4                         0.381816     628.319190                   1.654765   \n",
       "\n",
       "   ...  motion_outlier127  motion_outlier128  motion_outlier129  \\\n",
       "0  ...                0.0                0.0                0.0   \n",
       "1  ...                0.0                0.0                0.0   \n",
       "2  ...                0.0                0.0                0.0   \n",
       "3  ...                0.0                0.0                0.0   \n",
       "4  ...                0.0                0.0                0.0   \n",
       "\n",
       "   motion_outlier130  motion_outlier131  motion_outlier132  motion_outlier133  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1                0.0                0.0                0.0                0.0   \n",
       "2                0.0                0.0                0.0                0.0   \n",
       "3                0.0                0.0                0.0                0.0   \n",
       "4                0.0                0.0                0.0                0.0   \n",
       "\n",
       "   motion_outlier134  motion_outlier135  motion_outlier136  \n",
       "0                0.0                0.0                0.0  \n",
       "1                0.0                0.0                0.0  \n",
       "2                0.0                0.0                0.0  \n",
       "3                0.0                0.0                0.0  \n",
       "4                0.0                0.0                0.0  \n",
       "\n",
       "[5 rows x 389 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ds.get(file_list[0])\n",
    "\n",
    "confounds = pd.read_csv(file_list[0], sep='\\t')\n",
    "confounds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T02:55:52.635093Z",
     "start_time": "2020-05-15T02:55:52.630982Z"
    }
   },
   "source": [
    "What if we wanted to drop that file? Just like the CLI, we can use `ds.drop(file_name)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T00:41:51.097954Z",
     "start_time": "2020-07-04T00:41:48.727430Z"
    }
   },
   "outputs": [],
   "source": [
    "result = ds.drop(file_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that it is actually removed, let's try to load it again with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T00:41:53.302015Z",
     "start_time": "2020-07-04T00:41:53.028245Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File /Users/lukechang/Downloads/Sherlock/fmriprep/sub-01/func/sub-01_task-freerecall_desc-confounds_regressors.tsv does not exist: '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-01/func/sub-01_task-freerecall_desc-confounds_regressors.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-58d68c1a1fbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File /Users/lukechang/Downloads/Sherlock/fmriprep/sub-01/func/sub-01_task-freerecall_desc-confounds_regressors.tsv does not exist: '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-01/func/sub-01_task-freerecall_desc-confounds_regressors.tsv'"
     ]
    }
   ],
   "source": [
    "confounds = pd.read_csv(file_list[0], sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it was successfully removed.\n",
    "\n",
    "We can also load the entire dataset in one command if want using `ds.get(dataset='.', recursive=True)`. We are not going to do it right now as this will take awhile and require lots of free hard disk space.\n",
    "\n",
    "Let's actually download one of the files we will be using in the tutorial. First, let's use glob to get a list of all of the functional data that has been preprocessed by fmriprep, denoised, and smoothed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T00:42:05.562027Z",
     "start_time": "2020-07-04T00:42:05.527063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/lukechang/Downloads/Sherlock/fmriprep/sub-01/func/sub-01_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-01/func/sub-01_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-02/func/sub-02_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-02/func/sub-02_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-03/func/sub-03_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-03/func/sub-03_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-04/func/sub-04_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-04/func/sub-04_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-05/func/sub-05_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-05/func/sub-05_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-06/func/sub-06_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-06/func/sub-06_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-07/func/sub-07_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-07/func/sub-07_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-08/func/sub-08_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-08/func/sub-08_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-09/func/sub-09_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-09/func/sub-09_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-10/func/sub-10_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-10/func/sub-10_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-11/func/sub-11_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-11/func/sub-11_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-12/func/sub-12_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-12/func/sub-12_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-13/func/sub-13_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-13/func/sub-13_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-14/func/sub-14_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-14/func/sub-14_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-15/func/sub-15_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-15/func/sub-15_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-16/func/sub-16_denoise_crop_smooth6mm_task-sherlockPart1_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz',\n",
       " '/Users/lukechang/Downloads/Sherlock/fmriprep/sub-16/func/sub-16_denoise_crop_smooth6mm_task-sherlockPart2_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = glob.glob(os.path.join(sherlock_path, 'fmriprep', '*', 'func', '*crop*nii.gz'))\n",
    "file_list.sort()\n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T03:28:41.478323Z",
     "start_time": "2020-05-15T03:28:41.473643Z"
    }
   },
   "source": [
    "Now let's download the first subject's file using `ds.get()`. This file is 825mb, so this might take a few minutes depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T01:36:43.902456Z",
     "start_time": "2020-07-04T00:42:15.620200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='fmriprep/su .. bold.nii.gz', max=865032028.0, style=Progrâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = ds.get(file_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-15T02:34:11.627082Z",
     "start_time": "2020-05-15T02:34:11.622577Z"
    }
   },
   "source": [
    "How much of the dataset have we downloaded?  We can check the status of the annex using `ds.status(annex='all')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-04T01:45:35.519780Z",
     "start_time": "2020-07-04T01:45:31.639947Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1349 annex'd files (825.0 MB/109.0 GB present/total size)\n",
      "1349 annex'd files (825.0 MB/109.0 GB present/total size)\n"
     ]
    }
   ],
   "source": [
    "result = ds.status(annex='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that concludes our tutorial for how to download data for this course with datalad using both the command line interface and also the Python API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
